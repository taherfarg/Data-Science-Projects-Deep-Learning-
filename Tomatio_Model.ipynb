{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31pV6Bvx1sin"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "import matplotlib.pyplot as plt\n",
        "#add drive link\n",
        "from google.colab import drive\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "5zYr3XF40HBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!kaggle datasets download -d emmarex/plantdisease\n",
        "#!unzip plantdisease.zip\n"
      ],
      "metadata": {
        "id": "njMLlCKR0IVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#folder_to_delete = \"plantvillage/PlantVillage/Potato___healthy\"\n",
        "\n",
        "#try:\n",
        " # shutil.rmtree(folder_to_delete)\n",
        "  #print(\"Folder\", folder_to_delete, \"deleted successfully!\")\n",
        "#except OSError as e:\n",
        " # print(\"Error:\", e)\n"
      ],
      "metadata": {
        "id": "ofZF2L8S0gSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJUE0drQ1sip"
      },
      "source": [
        ".................................................................................................### Set all the Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LGEPq3Q1sip"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 224\n",
        "CHANNELS=3\n",
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4XORcB1sip"
      },
      "source": [
        "### Import data into tensorflow dataset object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI2XkEyA1siq"
      },
      "outputs": [],
      "source": [
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"plantvillage/PlantVillage\",\n",
        "    seed=123,\n",
        "    shuffle=True,\n",
        "    image_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcC9P5US1sis"
      },
      "outputs": [],
      "source": [
        "class_names = dataset.class_names\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvNZj2Af1sis"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in dataset.take(1):\n",
        "    print(image_batch.shape)\n",
        "    print(labels_batch.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_ZjsDQk1sis"
      },
      "source": [
        "As you can see above, each element in the dataset is a tuple. First element is a batch of 32 elements of images. Second element is a batch of 32 elements of class labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31PUaQqc1sit"
      },
      "source": [
        "### Visualize some of the images from our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb2fv9SZ1sit"
      },
      "outputs": [],
      "source": [
        "#print first 12 images\n",
        "plt.figure(figsize=(15, 15))\n",
        "for image_batch, labels_batch in dataset.take(1):\n",
        "    for i in range(8):\n",
        "        ax = plt.subplot(3, 4, i + 1)\n",
        "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels_batch[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4mKQGEK1sit"
      },
      "source": [
        "### Function to Split Dataset\n",
        "\n",
        "Dataset should be bifurcated into 3 subsets, namely:\n",
        "1. Training: Dataset to be used while training\n",
        "2. Validation: Dataset to be tested against while training\n",
        "3. Test: Dataset to be tested against after we trained a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUwJ0u0U1sit"
      },
      "outputs": [],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAiqxBkO1siv"
      },
      "outputs": [],
      "source": [
        "# train, test, validation\n",
        "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "\n",
        "    ds_size = len(ds)\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "\n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "\n",
        "    train_ds = ds.take(train_size)\n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "\n",
        "    return train_ds, val_ds, test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf_8C_oM1siv"
      },
      "outputs": [],
      "source": [
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2GaLqnf1siv"
      },
      "outputs": [],
      "source": [
        "len(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leYnpCzP1siv"
      },
      "outputs": [],
      "source": [
        "len(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfLW0d2t1siv"
      },
      "outputs": [],
      "source": [
        "len(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPx7Ucpi1siv"
      },
      "source": [
        "### Cache, Shuffle, and Prefetch the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLx4vgVT1siw"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4ewLWK01siw"
      },
      "source": [
        "## Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTl-VxS41siw"
      },
      "source": [
        "### Creating a Layer for Resizing and Normalization\n",
        "Before we feed our images to network, we should be resizing it to the desired size.\n",
        "Moreover, to improve model performance, we should normalize the image pixel value (keeping them in range 0 and 1 by dividing by 256).\n",
        "This should happen while training as well as inference. Hence we can add that as a layer in our Sequential Model.\n",
        "\n",
        "You might be thinking why do we need to resize (256,256) image to again (256,256). You are right we don't need to but this will be useful when we are done with the training and start using the model for predictions. At that time somone can supply an image that is not (256,256) and this layer will resize it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CL9GC471siw"
      },
      "outputs": [],
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  tf.keras.layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "  tf.keras.layers.Rescaling(1./255)])\n",
        "for image_batch, labels_batch in dataset.take(1):\n",
        "    print(image_batch.shape)\n",
        "    print(labels_batch.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "  tf.keras.layers.RandomZoom(0.2),\n",
        "  tf.keras.layers.RandomContrast(0.2),\n",
        "  tf.keras.layers.RandomBrightness(0.2),\n",
        "  tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
        "  tf.keras.layers.RandomCrop(IMAGE_SIZE, IMAGE_SIZE),\n",
        "  tf.keras.layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "])\n"
      ],
      "metadata": {
        "id": "vNXjfp_joF3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAJOjPvl1siy"
      },
      "source": [
        "### Model Architecture\n",
        "We use a CNN coupled with a Softmax activation in the output layer. We also add the initial layers for resizing, normalization and Data Augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzZ_sidS1siy"
      },
      "source": [
        "**We are going to use convolutional neural network (CNN) here. CNN is popular for image classification tasks. Watch below video to understand fundamentals of CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi-PLdKh1siy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "def resize_and_rescale(image, target_size=(224, 224), scale_factor=1.0):\n",
        "\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, target_size)\n",
        "    image = image / scale_factor\n",
        "\n",
        "    return image\n",
        "\n",
        "    resized_image = tf.image.resize(image, target_size)\n",
        "    rescaled_image = resized_image * scale_factor\n",
        "    return rescaled_image\n",
        "\n",
        "def data_augmentation(image):\n",
        "\n",
        "    image = tf.cast(image, tf.float32)\n",
        "\n",
        "    # Randomly flip the image horizontally\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "    # Randomly adjust brightness\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "\n",
        "    # Randomly apply horizontal flip\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "    # Randomly adjust brightness\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "\n",
        "    # Randomly adjust contrast\n",
        "    image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
        "\n",
        "    # Randomly adjust saturation\n",
        "    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Create MobileNet model with pre-trained weights (exclude top layer)\n",
        "base_model = MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add a global average pooling layer\n",
        "global_avg_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "# Add a dense output layer (e.g., for binary classification)\n",
        "output_layer = tf.keras.layers.Dense(16, activation='softmax')(global_avg_pooling_layer)\n",
        "\n",
        "# Combine the base model with the output layers\n",
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avANG2de1siy"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOWDiZpk1siz"
      },
      "source": [
        "### Compiling the Model\n",
        "We use `adam` Optimizer, `SparseCategoricalCrossentropy` for losses, `accuracy` as a metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zkbpv5HF1siz"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oOQbC-E1siz",
        "outputId": "413a63e0-90bd-481b-b8a9-4ae33ca8337f",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1,\n",
        "    epochs=20,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueD3-Het1siz"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s1hmU7h1siz"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV-G62c71si0"
      },
      "source": [
        "Scores is just a list containing loss and accuracy value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9K1GZ7O1si0"
      },
      "source": [
        "### Plotting the Accuracy and Loss Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqR5JQyw1si0"
      },
      "outputs": [],
      "source": [
        "history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcR5XzFi1si0"
      },
      "source": [
        "You can read documentation on history object here: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exLXpCZT1si0"
      },
      "outputs": [],
      "source": [
        "history.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUoWZsc61si1"
      },
      "outputs": [],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPkb_A9I1si1"
      },
      "outputs": [],
      "source": [
        "type(history.history['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc8YXA5n1si1"
      },
      "outputs": [],
      "source": [
        "len(history.history['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Soo1lvaj1si1"
      },
      "outputs": [],
      "source": [
        "history.history['loss'][:5] # show loss for first 5 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0zz0tQj1si1"
      },
      "outputs": [],
      "source": [
        "acc = history.history ['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV-81jNb1si2"
      },
      "outputs": [],
      "source": [
        "EPOCHS=20\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
        "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
        "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqSxb91f1si2"
      },
      "source": [
        "### Run prediction on a sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px-cY_1A1si2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "for images_batch, labels_batch in test_ds.take(1):\n",
        "\n",
        "    first_image = images_batch[0].numpy().astype('uint8')\n",
        "    first_label = labels_batch[0].numpy()\n",
        "\n",
        "    print(\"first image to predict\")\n",
        "    plt.imshow(first_image)\n",
        "    print(\"actual label:\",class_names[first_label])\n",
        "\n",
        "    batch_prediction = model.predict(images_batch)\n",
        "    print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rju1C4_51si2"
      },
      "source": [
        "### Write a function for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ_zQpKz1si2"
      },
      "outputs": [],
      "source": [
        "def predict(model, img):\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    predicted_class = class_names[np.argmax(predictions[0])]\n",
        "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "    return predicted_class, confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW8TWXuMVfX5"
      },
      "outputs": [],
      "source": [
        "#upload a photo and make a prediction\n",
        "#from IPython.display import Image, display\n",
        "#d#isplay(Image(filename='../test.jpg', width=300, height=300))\n",
        "\n",
        "\n",
        "#img = tf.keras.preprocessing.image.load_img(\n",
        "#   \"../test.jpg\", target_size=(IMAGE_SIZE,IMAGE_SIZE)\n",
        "#)\n",
        "#img\n",
        "\n",
        "#predicted_class, confidence = predict(model, img)\n",
        "\n",
        "#print(f\"this image is {confidence}% {predicted_class}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8Pqqm0I1si3"
      },
      "source": [
        "**Now run inference on few sample images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvaOCPCW1si3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for images, labels in test_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "        predicted_class, confidence = predict(model, images[i].numpy())\n",
        "        actual_class = class_names[labels[i]]\n",
        "\n",
        "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
        "\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q1pMqcJ1si3"
      },
      "source": [
        "### Saving the Model\n",
        "We append the model to the list of models as a new version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbcCGLve1si3"
      },
      "outputs": [],
      "source": [
        "model.save(\"Tomato_Model2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5bWBu8CVfX6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the Keras model\n",
        "model = tf.keras.models.load_model('Corn_Model2.h5')\n",
        "\n",
        "# Convert the model to TFLite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model to a file\n",
        "with open('Corn_Model2.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ],
      "metadata": {
        "id": "aFs6qD_NHWA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow\n"
      ],
      "metadata": {
        "id": "SXeEBeBjIcEA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}